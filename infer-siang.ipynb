{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":7573349,"sourceType":"datasetVersion","datasetId":4408970},{"sourceId":7593999,"sourceType":"datasetVersion","datasetId":4420159},{"sourceId":7596752,"sourceType":"datasetVersion","datasetId":4421943},{"sourceId":7596767,"sourceType":"datasetVersion","datasetId":4421956},{"sourceId":7596783,"sourceType":"datasetVersion","datasetId":4421969}],"dockerImageVersionId":30648,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"raw","source":"# !pip install ntlk numpy torch scikit-learn transformers","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport time\nimport datetime\nimport gc\nimport random\nimport re\n\n\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Subset\nfrom torch.utils.data import TensorDataset, Dataset, DataLoader, RandomSampler, SequentialSampler,random_split\n\nfrom sklearn.model_selection import train_test_split, KFold, StratifiedKFold\nfrom sklearn.metrics import classification_report, f1_score\n\nimport transformers\nfrom transformers import BertTokenizer, AutoTokenizer, BertModel, BertConfig, AutoModel, AdamW\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"execution":{"iopub.status.busy":"2024-02-09T16:31:28.950400Z","iopub.execute_input":"2024-02-09T16:31:28.950969Z","iopub.status.idle":"2024-02-09T16:31:43.134220Z","shell.execute_reply.started":"2024-02-09T16:31:28.950930Z","shell.execute_reply":"2024-02-09T16:31:43.132511Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"TOKENIZER_SCIBERT_PATH=\"/kaggle/input/tokenizerscibert/\"\nMODEL_SCIBERT_PATH=\"/kaggle/input/modelscibert/\"\nTEST_DATASET_PATH=\"/kaggle/input/test-csv/test.csv\"\nCUSTOM_MODEL_PATH=\"/kaggle/input/finetunemodel/model.bin\"","metadata":{"execution":{"iopub.status.busy":"2024-02-09T16:31:46.664987Z","iopub.execute_input":"2024-02-09T16:31:46.665967Z","iopub.status.idle":"2024-02-09T16:31:46.673994Z","shell.execute_reply.started":"2024-02-09T16:31:46.665916Z","shell.execute_reply":"2024-02-09T16:31:46.672311Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(TEST_DATASET_PATH)\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2024-02-09T16:31:52.770604Z","iopub.execute_input":"2024-02-09T16:31:52.771089Z","iopub.status.idle":"2024-02-09T16:31:53.193772Z","shell.execute_reply.started":"2024-02-09T16:31:52.771056Z","shell.execute_reply":"2024-02-09T16:31:53.192242Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['text'] = df['Title'] +\" \"+ df['Abstract']\ndel df['Title']\ndel df['Abstract']\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2024-02-09T16:31:57.509185Z","iopub.execute_input":"2024-02-09T16:31:57.509635Z","iopub.status.idle":"2024-02-09T16:31:57.560740Z","shell.execute_reply.started":"2024-02-09T16:31:57.509588Z","shell.execute_reply":"2024-02-09T16:31:57.558979Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def clean_text(text):\n    \n    text = text.lower()\n    \n    text = re.sub(r\"[^a-zA-Z?.!,Â¿]+\", \" \", text) # replacing everything with space except (a-z, A-Z, \".\", \"?\", \"!\", \",\")\n\n    text = re.sub(r\"http\\S+\", \"\",text) #Removing URLs \n    #text = re.sub(r\"http\", \"\",text)\n    \n    html=re.compile(r'<.*?>') \n    \n    text = html.sub(r'',text) #Removing html tags\n    \n    punctuations = '@#!?+&*[]-%.:/();$=><|{}^' + \"'`\" + '_'\n    for p in punctuations:\n        text = text.replace(p,'' )\n        \n    text = [word.lower() for word in text.split()]\n    \n    text = \" \".join(text) \n    \n    return text","metadata":{"execution":{"iopub.status.busy":"2024-02-09T16:32:01.779557Z","iopub.execute_input":"2024-02-09T16:32:01.779987Z","iopub.status.idle":"2024-02-09T16:32:01.789766Z","shell.execute_reply.started":"2024-02-09T16:32:01.779955Z","shell.execute_reply":"2024-02-09T16:32:01.788223Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['text'] = df['text'].apply(lambda x: clean_text(x))\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2024-02-09T16:32:05.309325Z","iopub.execute_input":"2024-02-09T16:32:05.309776Z","iopub.status.idle":"2024-02-09T16:32:07.090151Z","shell.execute_reply.started":"2024-02-09T16:32:05.309743Z","shell.execute_reply":"2024-02-09T16:32:07.088490Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"MAX_LEN = 512\ntokenizer = AutoTokenizer.from_pretrained(TOKENIZER_SCIBERT_PATH)","metadata":{"execution":{"iopub.status.busy":"2024-02-09T16:32:10.049610Z","iopub.execute_input":"2024-02-09T16:32:10.050502Z","iopub.status.idle":"2024-02-09T16:32:10.140694Z","shell.execute_reply.started":"2024-02-09T16:32:10.050453Z","shell.execute_reply":"2024-02-09T16:32:10.138703Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class BERTClass(torch.nn.Module):\n    def __init__(self):\n        super(BERTClass, self).__init__()\n        self.roberta = AutoModel.from_pretrained(MODEL_SCIBERT_PATH)\n        self.fc = torch.nn.Linear(768,57)\n    \n    def forward(self, ids, mask, token_type_ids):\n        _, features = self.roberta(ids, attention_mask = mask, token_type_ids = token_type_ids, return_dict=False)\n        output = self.fc(features)\n        return output\n  \n\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\nmodel = BERTClass()\nmodel_state_dict = torch.load(CUSTOM_MODEL_PATH, map_location=device)\nmodel.load_state_dict(model_state_dict)\nmodel.to(device)","metadata":{"execution":{"iopub.status.busy":"2024-02-09T16:32:17.621318Z","iopub.execute_input":"2024-02-09T16:32:17.621886Z","iopub.status.idle":"2024-02-09T16:32:28.236915Z","shell.execute_reply.started":"2024-02-09T16:32:17.621836Z","shell.execute_reply":"2024-02-09T16:32:28.234704Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class BERTDataset(Dataset):\n    def __init__(self, df, tokenizer, max_len):\n        self.df = df\n        self.max_len = max_len\n        self.text = df[\"text\"]\n        self.tokenizer = tokenizer\n        \n        \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, index):\n        text = self.text[index]\n        inputs = self.tokenizer.encode_plus(\n            text,\n            truncation=True,\n            add_special_tokens=True,\n            max_length=self.max_len,\n            padding='max_length',\n            return_token_type_ids=True\n        )\n        ids = inputs['input_ids']\n        mask = inputs['attention_mask']\n        token_type_ids = inputs[\"token_type_ids\"]\n        \n        return {\n            'ids': torch.tensor(ids, dtype=torch.long),\n            'mask': torch.tensor(mask, dtype=torch.long),\n            'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long),\n        }\n","metadata":{"execution":{"iopub.status.busy":"2024-02-09T09:32:57.237728Z","iopub.execute_input":"2024-02-09T09:32:57.238243Z","iopub.status.idle":"2024-02-09T09:32:57.250503Z","shell.execute_reply.started":"2024-02-09T09:32:57.238201Z","shell.execute_reply":"2024-02-09T09:32:57.247885Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_dataset = BERTDataset(df, tokenizer, MAX_LEN)","metadata":{"execution":{"iopub.status.busy":"2024-02-09T09:33:09.071136Z","iopub.execute_input":"2024-02-09T09:33:09.071569Z","iopub.status.idle":"2024-02-09T09:33:09.080315Z","shell.execute_reply.started":"2024-02-09T09:33:09.071535Z","shell.execute_reply":"2024-02-09T09:33:09.078622Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n\n# Initialize lists to store predictions\npredictions = []\n\n# Set the model in evaluation mode\nmodel.eval()\n\n# Iterate through the test data and make predictions\nwith torch.no_grad():\n    print(len(test_loader))\n    for index,batch in enumerate(test_loader):\n        input_ids = batch['ids'].to(device, dtype = torch.long)\n        mask = batch['mask'].to(device, dtype = torch.long)\n        token_type_ids = batch['token_type_ids'].to(device, dtype = torch.long)\n\n        # Forward pass\n        outputs = model(input_ids, mask = mask, token_type_ids=token_type_ids)\n\n        # Assuming your model outputs a single value per sample (regression task)\n        batch_predictions = outputs.squeeze().tolist()\n\n        # Append batch predictions to the list\n        predictions.extend(batch_predictions)\n        if index% 50==0: \n            print(f\"{index} completed\")\n\n# Create a new dataframe to store predictions\noutput_df = pd.DataFrame({'Prediction': predictions})","metadata":{"execution":{"iopub.status.busy":"2024-02-09T09:38:39.168297Z","iopub.execute_input":"2024-02-09T09:38:39.168843Z","iopub.status.idle":"2024-02-09T12:22:34.329334Z","shell.execute_reply.started":"2024-02-09T09:38:39.168804Z","shell.execute_reply":"2024-02-09T12:22:34.327642Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"output_df.head()","metadata":{"execution":{"iopub.status.busy":"2024-02-09T09:23:08.266131Z","iopub.execute_input":"2024-02-09T09:23:08.266506Z","iopub.status.idle":"2024-02-09T09:23:08.280008Z","shell.execute_reply.started":"2024-02-09T09:23:08.266477Z","shell.execute_reply":"2024-02-09T09:23:08.279121Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"replace_numbers = lambda x: [0 if i < -1.05 else 1 for i in x]\n\n# Apply the lambda function to each element in the DataFrame\noutput_df1 = output_df.applymap(replace_numbers)\ndf1 = pd.concat([df['Id'],output_df1['Prediction']],axis = 1)\n\ncolumn_titles = ['cs.AI','cs.AR','cs.CE','cs.CL','cs.CR','cs.CV','cs.DB','cs.DC','cs.DM','cs.GT','cs.IR','cs.IT','cs.LG','cs.LO','cs.NI','cs.OS','cs.PL','cs.RO','cs.SD','cs.SE','econ.EM','econ.GN','econ.TH','eess.AS','eess.IV','eess.SP','math.AC','math.AP','math.AT','math.CO','math.CV','math.GR','math.IT','math.LO','math.NT','math.PR','math.QA','math.ST','q-bio.BM','q-bio.CB','q-bio.GN','q-bio.MN','q-bio.NC','q-bio.TO','q-fin.CP','q-fin.EC','q-fin.GN','q-fin.MF','q-fin.PM','q-fin.PR','q-fin.RM','q-fin.TR','stat.AP','stat.CO','stat.ME','stat.ML','stat.TH']\n# Initialize an empty dictionary to store the new data\nnew_data = {}\n\n# Add the 'ColumnA' data to the new data dictionary\nnew_data['Id'] = df['Id']\n\n# Iterate through the list of column titles and the corresponding values from 'ColumnB'\nfor i, title in enumerate(column_titles):\n    new_data[title] = output_df1['Prediction'].apply(lambda x: x[i])\n\n# Create the new DataFrame\nnew_df = pd.DataFrame(new_data)","metadata":{"execution":{"iopub.status.busy":"2024-02-09T09:23:12.650656Z","iopub.execute_input":"2024-02-09T09:23:12.651519Z","iopub.status.idle":"2024-02-09T09:23:13.157066Z","shell.execute_reply.started":"2024-02-09T09:23:12.651487Z","shell.execute_reply":"2024-02-09T09:23:13.156302Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"new_df.head(10)","metadata":{"execution":{"iopub.status.busy":"2024-02-09T09:23:18.743974Z","iopub.execute_input":"2024-02-09T09:23:18.744832Z","iopub.status.idle":"2024-02-09T09:23:18.762837Z","shell.execute_reply.started":"2024-02-09T09:23:18.744796Z","shell.execute_reply":"2024-02-09T09:23:18.761954Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df2 = pd.read_csv(\"../input/sample-csv/sample_submission.csv\")","metadata":{"execution":{"iopub.status.busy":"2024-02-09T09:23:24.033166Z","iopub.execute_input":"2024-02-09T09:23:24.033547Z","iopub.status.idle":"2024-02-09T09:23:24.079861Z","shell.execute_reply.started":"2024-02-09T09:23:24.033520Z","shell.execute_reply":"2024-02-09T09:23:24.079035Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"column_titles = df2.columns[0:58].tolist()\n\nnew_df = new_df[column_titles]\ncsv_file_path = 'siang.csv'  \n\n# Save the DataFrame to a CSV file\nnew_df.to_csv(csv_file_path, index=False)","metadata":{"execution":{"iopub.status.busy":"2024-02-09T09:23:27.687553Z","iopub.execute_input":"2024-02-09T09:23:27.687893Z","iopub.status.idle":"2024-02-09T09:23:27.883730Z","shell.execute_reply.started":"2024-02-09T09:23:27.687868Z","shell.execute_reply":"2024-02-09T09:23:27.882694Z"},"trusted":true},"execution_count":null,"outputs":[]}]}